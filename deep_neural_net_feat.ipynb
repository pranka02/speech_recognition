{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import tensorflow as tf\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-424.004655</td>\n",
       "      <td>85.886018</td>\n",
       "      <td>-19.391035</td>\n",
       "      <td>19.548873</td>\n",
       "      <td>-3.152061</td>\n",
       "      <td>-3.135796</td>\n",
       "      <td>-5.586479</td>\n",
       "      <td>2.204532</td>\n",
       "      <td>-0.968167</td>\n",
       "      <td>-4.146447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756196</td>\n",
       "      <td>0.754540</td>\n",
       "      <td>18.187436</td>\n",
       "      <td>14.309552</td>\n",
       "      <td>16.744301</td>\n",
       "      <td>16.287958</td>\n",
       "      <td>16.495040</td>\n",
       "      <td>18.176403</td>\n",
       "      <td>53.666413</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-427.845940</td>\n",
       "      <td>61.444910</td>\n",
       "      <td>-69.906503</td>\n",
       "      <td>75.739853</td>\n",
       "      <td>-35.569725</td>\n",
       "      <td>9.582659</td>\n",
       "      <td>6.669224</td>\n",
       "      <td>5.555409</td>\n",
       "      <td>4.426516</td>\n",
       "      <td>9.670583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789944</td>\n",
       "      <td>0.717734</td>\n",
       "      <td>23.542518</td>\n",
       "      <td>16.525604</td>\n",
       "      <td>19.920645</td>\n",
       "      <td>17.190587</td>\n",
       "      <td>18.389313</td>\n",
       "      <td>21.918735</td>\n",
       "      <td>60.188674</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-327.288344</td>\n",
       "      <td>107.655145</td>\n",
       "      <td>-85.208783</td>\n",
       "      <td>-4.627603</td>\n",
       "      <td>-34.472271</td>\n",
       "      <td>-2.624659</td>\n",
       "      <td>-18.956204</td>\n",
       "      <td>-6.853750</td>\n",
       "      <td>-7.975197</td>\n",
       "      <td>-20.111568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.663733</td>\n",
       "      <td>31.389790</td>\n",
       "      <td>14.436285</td>\n",
       "      <td>17.012344</td>\n",
       "      <td>18.676632</td>\n",
       "      <td>18.853558</td>\n",
       "      <td>19.082480</td>\n",
       "      <td>57.331269</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-341.501762</td>\n",
       "      <td>107.211360</td>\n",
       "      <td>-90.836330</td>\n",
       "      <td>-0.098215</td>\n",
       "      <td>-33.703336</td>\n",
       "      <td>-3.610792</td>\n",
       "      <td>-29.906583</td>\n",
       "      <td>-9.599740</td>\n",
       "      <td>-18.541331</td>\n",
       "      <td>-23.105156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536866</td>\n",
       "      <td>0.596243</td>\n",
       "      <td>29.135632</td>\n",
       "      <td>14.979695</td>\n",
       "      <td>17.966184</td>\n",
       "      <td>17.527041</td>\n",
       "      <td>17.873409</td>\n",
       "      <td>20.326471</td>\n",
       "      <td>57.930192</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-442.097720</td>\n",
       "      <td>142.172651</td>\n",
       "      <td>-25.851881</td>\n",
       "      <td>33.580954</td>\n",
       "      <td>-4.230062</td>\n",
       "      <td>12.438396</td>\n",
       "      <td>-16.501494</td>\n",
       "      <td>12.557016</td>\n",
       "      <td>0.892619</td>\n",
       "      <td>-2.308974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361471</td>\n",
       "      <td>0.472670</td>\n",
       "      <td>26.285881</td>\n",
       "      <td>19.839796</td>\n",
       "      <td>20.518118</td>\n",
       "      <td>19.795706</td>\n",
       "      <td>18.634939</td>\n",
       "      <td>17.751166</td>\n",
       "      <td>56.695714</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-481.401211</td>\n",
       "      <td>96.320072</td>\n",
       "      <td>-3.340789</td>\n",
       "      <td>6.039630</td>\n",
       "      <td>-1.719361</td>\n",
       "      <td>16.746752</td>\n",
       "      <td>-0.383682</td>\n",
       "      <td>-8.960226</td>\n",
       "      <td>6.744356</td>\n",
       "      <td>-1.369229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626463</td>\n",
       "      <td>0.570527</td>\n",
       "      <td>20.251495</td>\n",
       "      <td>15.690428</td>\n",
       "      <td>17.070937</td>\n",
       "      <td>16.076208</td>\n",
       "      <td>22.293984</td>\n",
       "      <td>21.240883</td>\n",
       "      <td>51.277368</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2          3          4          5   \\\n",
       "0 -424.004655   85.886018 -19.391035  19.548873  -3.152061  -3.135796   \n",
       "1 -427.845940   61.444910 -69.906503  75.739853 -35.569725   9.582659   \n",
       "2 -327.288344  107.655145 -85.208783  -4.627603 -34.472271  -2.624659   \n",
       "3 -341.501762  107.211360 -90.836330  -0.098215 -33.703336  -3.610792   \n",
       "4 -442.097720  142.172651 -25.851881  33.580954  -4.230062  12.438396   \n",
       "5 -481.401211   96.320072  -3.340789   6.039630  -1.719361  16.746752   \n",
       "\n",
       "          6          7          8          9   ...         50        51  \\\n",
       "0  -5.586479   2.204532  -0.968167  -4.146447  ...   0.756196  0.754540   \n",
       "1   6.669224   5.555409   4.426516   9.670583  ...   0.789944  0.717734   \n",
       "2 -18.956204  -6.853750  -7.975197 -20.111568  ...   0.553500  0.663733   \n",
       "3 -29.906583  -9.599740 -18.541331 -23.105156  ...   0.536866  0.596243   \n",
       "4 -16.501494  12.557016   0.892619  -2.308974  ...   0.361471  0.472670   \n",
       "5  -0.383682  -8.960226   6.744356  -1.369229  ...   0.626463  0.570527   \n",
       "\n",
       "          52         53         54         55         56         57  \\\n",
       "0  18.187436  14.309552  16.744301  16.287958  16.495040  18.176403   \n",
       "1  23.542518  16.525604  19.920645  17.190587  18.389313  21.918735   \n",
       "2  31.389790  14.436285  17.012344  18.676632  18.853558  19.082480   \n",
       "3  29.135632  14.979695  17.966184  17.527041  17.873409  20.326471   \n",
       "4  26.285881  19.839796  20.518118  19.795706  18.634939  17.751166   \n",
       "5  20.251495  15.690428  17.070937  16.076208  22.293984  21.240883   \n",
       "\n",
       "          58    59  \n",
       "0  53.666413  down  \n",
       "1  60.188674  down  \n",
       "2  57.331269  down  \n",
       "3  57.930192  down  \n",
       "4  56.695714  down  \n",
       "5  51.277368  down  \n",
       "\n",
       "[6 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train/features.csv',header = None)\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14478</th>\n",
       "      <td>-333.681364</td>\n",
       "      <td>130.329232</td>\n",
       "      <td>0.321711</td>\n",
       "      <td>37.352478</td>\n",
       "      <td>8.991458</td>\n",
       "      <td>21.009426</td>\n",
       "      <td>-7.347120</td>\n",
       "      <td>2.926471</td>\n",
       "      <td>9.192337</td>\n",
       "      <td>-1.285272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656229</td>\n",
       "      <td>0.618991</td>\n",
       "      <td>20.608630</td>\n",
       "      <td>14.823694</td>\n",
       "      <td>16.085269</td>\n",
       "      <td>15.570495</td>\n",
       "      <td>19.752411</td>\n",
       "      <td>19.580212</td>\n",
       "      <td>49.649687</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53779</th>\n",
       "      <td>-193.152434</td>\n",
       "      <td>122.221520</td>\n",
       "      <td>-51.292561</td>\n",
       "      <td>50.933137</td>\n",
       "      <td>-48.466207</td>\n",
       "      <td>35.913824</td>\n",
       "      <td>-27.859928</td>\n",
       "      <td>17.481937</td>\n",
       "      <td>-7.220476</td>\n",
       "      <td>4.397814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571067</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>13.993230</td>\n",
       "      <td>13.438817</td>\n",
       "      <td>15.450493</td>\n",
       "      <td>15.201903</td>\n",
       "      <td>17.873088</td>\n",
       "      <td>16.969728</td>\n",
       "      <td>67.328210</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39324</th>\n",
       "      <td>-397.433994</td>\n",
       "      <td>135.709828</td>\n",
       "      <td>-56.030748</td>\n",
       "      <td>43.119616</td>\n",
       "      <td>10.883204</td>\n",
       "      <td>21.592556</td>\n",
       "      <td>11.034850</td>\n",
       "      <td>9.081485</td>\n",
       "      <td>8.867335</td>\n",
       "      <td>16.951063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625539</td>\n",
       "      <td>0.609749</td>\n",
       "      <td>22.135568</td>\n",
       "      <td>17.568748</td>\n",
       "      <td>15.915933</td>\n",
       "      <td>13.979939</td>\n",
       "      <td>18.450613</td>\n",
       "      <td>22.024194</td>\n",
       "      <td>56.153385</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39368</th>\n",
       "      <td>-475.983507</td>\n",
       "      <td>97.149996</td>\n",
       "      <td>-13.002183</td>\n",
       "      <td>26.815174</td>\n",
       "      <td>7.942826</td>\n",
       "      <td>-4.800929</td>\n",
       "      <td>-1.142322</td>\n",
       "      <td>-8.006042</td>\n",
       "      <td>2.259144</td>\n",
       "      <td>0.571355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623862</td>\n",
       "      <td>0.685052</td>\n",
       "      <td>18.429155</td>\n",
       "      <td>14.634313</td>\n",
       "      <td>18.238495</td>\n",
       "      <td>15.569912</td>\n",
       "      <td>17.027991</td>\n",
       "      <td>21.011901</td>\n",
       "      <td>49.624668</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39068</th>\n",
       "      <td>-499.078682</td>\n",
       "      <td>123.405728</td>\n",
       "      <td>-29.477016</td>\n",
       "      <td>68.025884</td>\n",
       "      <td>-16.589553</td>\n",
       "      <td>29.186493</td>\n",
       "      <td>0.409351</td>\n",
       "      <td>2.754675</td>\n",
       "      <td>-1.199870</td>\n",
       "      <td>12.231962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787645</td>\n",
       "      <td>0.696109</td>\n",
       "      <td>22.875983</td>\n",
       "      <td>11.440279</td>\n",
       "      <td>12.622149</td>\n",
       "      <td>13.358987</td>\n",
       "      <td>15.617734</td>\n",
       "      <td>18.389820</td>\n",
       "      <td>57.264418</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>-583.553439</td>\n",
       "      <td>118.171635</td>\n",
       "      <td>-9.595871</td>\n",
       "      <td>-10.589174</td>\n",
       "      <td>-12.837243</td>\n",
       "      <td>2.043973</td>\n",
       "      <td>18.265363</td>\n",
       "      <td>-9.853912</td>\n",
       "      <td>-16.418323</td>\n",
       "      <td>1.046255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745603</td>\n",
       "      <td>0.613810</td>\n",
       "      <td>22.796352</td>\n",
       "      <td>14.502942</td>\n",
       "      <td>17.453675</td>\n",
       "      <td>16.153588</td>\n",
       "      <td>18.816369</td>\n",
       "      <td>20.039646</td>\n",
       "      <td>50.547378</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1          2          3          4          5   \\\n",
       "14478 -333.681364  130.329232   0.321711  37.352478   8.991458  21.009426   \n",
       "53779 -193.152434  122.221520 -51.292561  50.933137 -48.466207  35.913824   \n",
       "39324 -397.433994  135.709828 -56.030748  43.119616  10.883204  21.592556   \n",
       "39368 -475.983507   97.149996 -13.002183  26.815174   7.942826  -4.800929   \n",
       "39068 -499.078682  123.405728 -29.477016  68.025884 -16.589553  29.186493   \n",
       "13000 -583.553439  118.171635  -9.595871 -10.589174 -12.837243   2.043973   \n",
       "\n",
       "              6          7          8          9    ...           50  \\\n",
       "14478  -7.347120   2.926471   9.192337  -1.285272   ...     0.656229   \n",
       "53779 -27.859928  17.481937  -7.220476   4.397814   ...     0.571067   \n",
       "39324  11.034850   9.081485   8.867335  16.951063   ...     0.625539   \n",
       "39368  -1.142322  -8.006042   2.259144   0.571355   ...     0.623862   \n",
       "39068   0.409351   2.754675  -1.199870  12.231962   ...     0.787645   \n",
       "13000  18.265363  -9.853912 -16.418323   1.046255   ...     0.745603   \n",
       "\n",
       "             51         52         53         54         55         56  \\\n",
       "14478  0.618991  20.608630  14.823694  16.085269  15.570495  19.752411   \n",
       "53779  0.612054  13.993230  13.438817  15.450493  15.201903  17.873088   \n",
       "39324  0.609749  22.135568  17.568748  15.915933  13.979939  18.450613   \n",
       "39368  0.685052  18.429155  14.634313  18.238495  15.569912  17.027991   \n",
       "39068  0.696109  22.875983  11.440279  12.622149  13.358987  15.617734   \n",
       "13000  0.613810  22.796352  14.502942  17.453675  16.153588  18.816369   \n",
       "\n",
       "              57         58       59  \n",
       "14478  19.580212  49.649687    right  \n",
       "53779  16.969728  67.328210  unknown  \n",
       "39324  22.024194  56.153385  unknown  \n",
       "39368  21.011901  49.624668  unknown  \n",
       "39068  18.389820  57.264418  unknown  \n",
       "13000  20.039646  50.547378       on  \n",
       "\n",
       "[6 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df)\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 60000\n",
    "features = np.array(df)\n",
    "tr_x = features[:tr,0:59]\n",
    "tr_y = features[:tr,59]\n",
    "val_x = features[tr:,0:59]\n",
    "val_y = features[tr:,59]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mean = np.mean(tr_x, axis=0)\n",
    "tr_std = np.std(tr_x, axis = 0,dtype=np.float64)\n",
    "tr_xp = (tr_x - tr_mean[None,:])/tr_std[None,:]\n",
    "\n",
    "val_mean = np.mean(val_x, axis=0)\n",
    "val_std = np.std(val_x, axis = 0,dtype=np.float64)\n",
    "val_xp = (val_x - val_mean[None,:])/val_std[None,:]\n",
    "\n",
    "lab = LabelEncoder()\n",
    "tr_yp= lab.fit_transform(tr_y)\n",
    "val_yp= lab.fit_transform(val_y)\n",
    "\n",
    "n_words= np.unique(tr_yp)\n",
    "n_classes = len(n_words)\n",
    "n_features = tr_xp.shape[1]\n",
    "\n",
    "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(range(n_classes))\n",
    "tr_yoh = label_binarizer.transform(tr_yp)\n",
    "val_yoh = label_binarizer.transform(val_yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components ='mle', svd_solver = 'full')\n",
    "pca.fit(tr_xp)\n",
    "tr_pca = pca.transform(tr_xp)\n",
    "val_pca = pca.transform(val_xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple 3-layer deep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 700\n",
    "n_nodes_hl2 = 700\n",
    "n_nodes_hl3 = 100\n",
    "\n",
    "batch_size = 200\n",
    "# one epoch = one cycle of feed-forward and backprop\n",
    "n_epochs = 30\n",
    "\n",
    "x = tf.placeholder('float',[None,n_features])\n",
    "y = tf.placeholder('float',[None,n_classes])\n",
    "epoch_losses =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "\n",
    "    # initializing weights and biases for the hidden layers and the output layer\n",
    "    hidden_l1 = {'weights': tf.Variable(tf.random_normal([n_features,n_nodes_hl1])), \n",
    "                 'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_l2 = {'weights': tf.Variable(tf.random_normal([n_nodes_hl1,n_nodes_hl2])), \n",
    "                 'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_l3 = {'weights': tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl3])), \n",
    "                 'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_l = {'weights': tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])), \n",
    "                 'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    # computing the ouput of each layer and applying a non-linearity at the end of each layer computation\n",
    "    l1 = tf.add(tf.matmul(data, hidden_l1['weights']), hidden_l1['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1, hidden_l2['weights']), hidden_l2['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2, hidden_l3['weights']), hidden_l3['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.add(tf.matmul(l3, output_l['weights']), output_l['biases'])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "\n",
    "    # learning rate = 0.001\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "    # one epoch = one cycle of feed-forward and backprop\n",
    "    n_epochs = 30\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0\n",
    "            for index, offset in enumerate(range(0, tr, batch_size)):\n",
    "                x_epoch, y_epoch = np.array(tr_xp[offset: offset + batch_size,:]), np.array(tr_yoh[offset: offset + batch_size])\n",
    "                _, c = sess.run([optimizer, cost], feed_dict ={x:x_epoch, y:y_epoch}) \n",
    "                epoch_loss +=c\n",
    "            epoch_losses.append(epoch_loss)\n",
    "            if (epoch%10 == 0):\n",
    "                    print ('Epoch', epoch, 'completed out of', n_epochs, 'loss:', epoch_loss)\n",
    "                    \n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy  = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', accuracy.eval({x:val_xp, y:val_yoh}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 30 loss: 1208270.10965\n",
      "Epoch 10 completed out of 30 loss: 471.758314252\n",
      "Epoch 20 completed out of 30 loss: 458.031672359\n",
      "Accuracy: 0.628343\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d0dadcd080>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEWCAYAAAAw6c+oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5ARqZtYgJ1AzswY5gZqZNcgJ1MysQf8faigvjUaoBxAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d0dadc4e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_title('Loss vs Epoch')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.plot(np.arange(0,30),np.asarray(epoch_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

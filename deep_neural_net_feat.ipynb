{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import tensorflow as tf \n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-424.004655</td>\n",
       "      <td>85.886018</td>\n",
       "      <td>-19.391035</td>\n",
       "      <td>19.548873</td>\n",
       "      <td>-3.152061</td>\n",
       "      <td>-3.135796</td>\n",
       "      <td>-5.586479</td>\n",
       "      <td>2.204532</td>\n",
       "      <td>-0.968167</td>\n",
       "      <td>-4.146447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756196</td>\n",
       "      <td>0.754540</td>\n",
       "      <td>18.187436</td>\n",
       "      <td>14.309552</td>\n",
       "      <td>16.744301</td>\n",
       "      <td>16.287958</td>\n",
       "      <td>16.495040</td>\n",
       "      <td>18.176403</td>\n",
       "      <td>53.666413</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-427.845940</td>\n",
       "      <td>61.444910</td>\n",
       "      <td>-69.906503</td>\n",
       "      <td>75.739853</td>\n",
       "      <td>-35.569725</td>\n",
       "      <td>9.582659</td>\n",
       "      <td>6.669224</td>\n",
       "      <td>5.555409</td>\n",
       "      <td>4.426516</td>\n",
       "      <td>9.670583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789944</td>\n",
       "      <td>0.717734</td>\n",
       "      <td>23.542518</td>\n",
       "      <td>16.525604</td>\n",
       "      <td>19.920645</td>\n",
       "      <td>17.190587</td>\n",
       "      <td>18.389313</td>\n",
       "      <td>21.918735</td>\n",
       "      <td>60.188674</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-327.288344</td>\n",
       "      <td>107.655145</td>\n",
       "      <td>-85.208783</td>\n",
       "      <td>-4.627603</td>\n",
       "      <td>-34.472271</td>\n",
       "      <td>-2.624659</td>\n",
       "      <td>-18.956204</td>\n",
       "      <td>-6.853750</td>\n",
       "      <td>-7.975197</td>\n",
       "      <td>-20.111568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.663733</td>\n",
       "      <td>31.389790</td>\n",
       "      <td>14.436285</td>\n",
       "      <td>17.012344</td>\n",
       "      <td>18.676632</td>\n",
       "      <td>18.853558</td>\n",
       "      <td>19.082480</td>\n",
       "      <td>57.331269</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-341.501762</td>\n",
       "      <td>107.211360</td>\n",
       "      <td>-90.836330</td>\n",
       "      <td>-0.098215</td>\n",
       "      <td>-33.703336</td>\n",
       "      <td>-3.610792</td>\n",
       "      <td>-29.906583</td>\n",
       "      <td>-9.599740</td>\n",
       "      <td>-18.541331</td>\n",
       "      <td>-23.105156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536866</td>\n",
       "      <td>0.596243</td>\n",
       "      <td>29.135632</td>\n",
       "      <td>14.979695</td>\n",
       "      <td>17.966184</td>\n",
       "      <td>17.527041</td>\n",
       "      <td>17.873409</td>\n",
       "      <td>20.326471</td>\n",
       "      <td>57.930192</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-442.097720</td>\n",
       "      <td>142.172651</td>\n",
       "      <td>-25.851881</td>\n",
       "      <td>33.580954</td>\n",
       "      <td>-4.230062</td>\n",
       "      <td>12.438396</td>\n",
       "      <td>-16.501494</td>\n",
       "      <td>12.557016</td>\n",
       "      <td>0.892619</td>\n",
       "      <td>-2.308974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361471</td>\n",
       "      <td>0.472670</td>\n",
       "      <td>26.285881</td>\n",
       "      <td>19.839796</td>\n",
       "      <td>20.518118</td>\n",
       "      <td>19.795706</td>\n",
       "      <td>18.634939</td>\n",
       "      <td>17.751166</td>\n",
       "      <td>56.695714</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-481.401211</td>\n",
       "      <td>96.320072</td>\n",
       "      <td>-3.340789</td>\n",
       "      <td>6.039630</td>\n",
       "      <td>-1.719361</td>\n",
       "      <td>16.746752</td>\n",
       "      <td>-0.383682</td>\n",
       "      <td>-8.960226</td>\n",
       "      <td>6.744356</td>\n",
       "      <td>-1.369229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626463</td>\n",
       "      <td>0.570527</td>\n",
       "      <td>20.251495</td>\n",
       "      <td>15.690428</td>\n",
       "      <td>17.070937</td>\n",
       "      <td>16.076208</td>\n",
       "      <td>22.293984</td>\n",
       "      <td>21.240883</td>\n",
       "      <td>51.277368</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2          3          4          5   \\\n",
       "0 -424.004655   85.886018 -19.391035  19.548873  -3.152061  -3.135796   \n",
       "1 -427.845940   61.444910 -69.906503  75.739853 -35.569725   9.582659   \n",
       "2 -327.288344  107.655145 -85.208783  -4.627603 -34.472271  -2.624659   \n",
       "3 -341.501762  107.211360 -90.836330  -0.098215 -33.703336  -3.610792   \n",
       "4 -442.097720  142.172651 -25.851881  33.580954  -4.230062  12.438396   \n",
       "5 -481.401211   96.320072  -3.340789   6.039630  -1.719361  16.746752   \n",
       "\n",
       "          6          7          8          9   ...         50        51  \\\n",
       "0  -5.586479   2.204532  -0.968167  -4.146447  ...   0.756196  0.754540   \n",
       "1   6.669224   5.555409   4.426516   9.670583  ...   0.789944  0.717734   \n",
       "2 -18.956204  -6.853750  -7.975197 -20.111568  ...   0.553500  0.663733   \n",
       "3 -29.906583  -9.599740 -18.541331 -23.105156  ...   0.536866  0.596243   \n",
       "4 -16.501494  12.557016   0.892619  -2.308974  ...   0.361471  0.472670   \n",
       "5  -0.383682  -8.960226   6.744356  -1.369229  ...   0.626463  0.570527   \n",
       "\n",
       "          52         53         54         55         56         57  \\\n",
       "0  18.187436  14.309552  16.744301  16.287958  16.495040  18.176403   \n",
       "1  23.542518  16.525604  19.920645  17.190587  18.389313  21.918735   \n",
       "2  31.389790  14.436285  17.012344  18.676632  18.853558  19.082480   \n",
       "3  29.135632  14.979695  17.966184  17.527041  17.873409  20.326471   \n",
       "4  26.285881  19.839796  20.518118  19.795706  18.634939  17.751166   \n",
       "5  20.251495  15.690428  17.070937  16.076208  22.293984  21.240883   \n",
       "\n",
       "          58    59  \n",
       "0  53.666413  down  \n",
       "1  60.188674  down  \n",
       "2  57.331269  down  \n",
       "3  57.930192  down  \n",
       "4  56.695714  down  \n",
       "5  51.277368  down  \n",
       "\n",
       "[6 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train/features.csv',header = None)\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>-278.332452</td>\n",
       "      <td>122.548205</td>\n",
       "      <td>17.836560</td>\n",
       "      <td>38.100128</td>\n",
       "      <td>3.673416</td>\n",
       "      <td>22.453465</td>\n",
       "      <td>3.796170</td>\n",
       "      <td>3.069669</td>\n",
       "      <td>4.242937</td>\n",
       "      <td>4.012372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801212</td>\n",
       "      <td>0.763200</td>\n",
       "      <td>16.460100</td>\n",
       "      <td>11.475269</td>\n",
       "      <td>14.589060</td>\n",
       "      <td>13.222518</td>\n",
       "      <td>15.129527</td>\n",
       "      <td>14.882141</td>\n",
       "      <td>53.166476</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30848</th>\n",
       "      <td>-396.004597</td>\n",
       "      <td>118.417287</td>\n",
       "      <td>-56.165559</td>\n",
       "      <td>-17.718862</td>\n",
       "      <td>-7.758987</td>\n",
       "      <td>-1.921056</td>\n",
       "      <td>-5.011773</td>\n",
       "      <td>-12.714256</td>\n",
       "      <td>1.477790</td>\n",
       "      <td>-8.460589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651782</td>\n",
       "      <td>0.693271</td>\n",
       "      <td>23.868738</td>\n",
       "      <td>17.087911</td>\n",
       "      <td>16.778028</td>\n",
       "      <td>16.785871</td>\n",
       "      <td>22.319176</td>\n",
       "      <td>20.813865</td>\n",
       "      <td>47.732244</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26687</th>\n",
       "      <td>-459.320593</td>\n",
       "      <td>86.033119</td>\n",
       "      <td>-34.166625</td>\n",
       "      <td>26.486928</td>\n",
       "      <td>-4.518112</td>\n",
       "      <td>-10.451871</td>\n",
       "      <td>-17.674859</td>\n",
       "      <td>-13.664492</td>\n",
       "      <td>-18.481547</td>\n",
       "      <td>-8.477611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723049</td>\n",
       "      <td>0.564621</td>\n",
       "      <td>17.176930</td>\n",
       "      <td>11.393799</td>\n",
       "      <td>16.169262</td>\n",
       "      <td>16.841237</td>\n",
       "      <td>17.982451</td>\n",
       "      <td>21.097822</td>\n",
       "      <td>56.996317</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7525</th>\n",
       "      <td>-434.909854</td>\n",
       "      <td>125.504726</td>\n",
       "      <td>-68.867853</td>\n",
       "      <td>-23.416314</td>\n",
       "      <td>-50.862376</td>\n",
       "      <td>-35.603120</td>\n",
       "      <td>-44.487021</td>\n",
       "      <td>-34.664457</td>\n",
       "      <td>-23.995675</td>\n",
       "      <td>-17.629907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707256</td>\n",
       "      <td>0.770657</td>\n",
       "      <td>16.431083</td>\n",
       "      <td>19.923425</td>\n",
       "      <td>15.502728</td>\n",
       "      <td>16.357902</td>\n",
       "      <td>19.036731</td>\n",
       "      <td>21.465307</td>\n",
       "      <td>53.337011</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46441</th>\n",
       "      <td>-514.006214</td>\n",
       "      <td>114.173333</td>\n",
       "      <td>-28.676594</td>\n",
       "      <td>85.126040</td>\n",
       "      <td>-38.347778</td>\n",
       "      <td>22.801841</td>\n",
       "      <td>2.784333</td>\n",
       "      <td>4.392395</td>\n",
       "      <td>7.778591</td>\n",
       "      <td>-6.709243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566722</td>\n",
       "      <td>0.583612</td>\n",
       "      <td>16.960252</td>\n",
       "      <td>12.600773</td>\n",
       "      <td>15.191264</td>\n",
       "      <td>16.295243</td>\n",
       "      <td>17.753734</td>\n",
       "      <td>20.810784</td>\n",
       "      <td>58.502929</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14135</th>\n",
       "      <td>-504.361062</td>\n",
       "      <td>134.850995</td>\n",
       "      <td>-47.825649</td>\n",
       "      <td>53.285514</td>\n",
       "      <td>-48.107859</td>\n",
       "      <td>25.662676</td>\n",
       "      <td>-22.636735</td>\n",
       "      <td>17.088560</td>\n",
       "      <td>-5.311794</td>\n",
       "      <td>1.440970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850959</td>\n",
       "      <td>0.746200</td>\n",
       "      <td>16.831720</td>\n",
       "      <td>16.474822</td>\n",
       "      <td>16.902862</td>\n",
       "      <td>17.215572</td>\n",
       "      <td>15.038436</td>\n",
       "      <td>16.477407</td>\n",
       "      <td>66.502537</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1          2          3          4          5   \\\n",
       "6100  -278.332452  122.548205  17.836560  38.100128   3.673416  22.453465   \n",
       "30848 -396.004597  118.417287 -56.165559 -17.718862  -7.758987  -1.921056   \n",
       "26687 -459.320593   86.033119 -34.166625  26.486928  -4.518112 -10.451871   \n",
       "7525  -434.909854  125.504726 -68.867853 -23.416314 -50.862376 -35.603120   \n",
       "46441 -514.006214  114.173333 -28.676594  85.126040 -38.347778  22.801841   \n",
       "14135 -504.361062  134.850995 -47.825649  53.285514 -48.107859  25.662676   \n",
       "\n",
       "              6          7          8          9    ...           50  \\\n",
       "6100    3.796170   3.069669   4.242937   4.012372   ...     0.801212   \n",
       "30848  -5.011773 -12.714256   1.477790  -8.460589   ...     0.651782   \n",
       "26687 -17.674859 -13.664492 -18.481547  -8.477611   ...     0.723049   \n",
       "7525  -44.487021 -34.664457 -23.995675 -17.629907   ...     0.707256   \n",
       "46441   2.784333   4.392395   7.778591  -6.709243   ...     0.566722   \n",
       "14135 -22.636735  17.088560  -5.311794   1.440970   ...     0.850959   \n",
       "\n",
       "             51         52         53         54         55         56  \\\n",
       "6100   0.763200  16.460100  11.475269  14.589060  13.222518  15.129527   \n",
       "30848  0.693271  23.868738  17.087911  16.778028  16.785871  22.319176   \n",
       "26687  0.564621  17.176930  11.393799  16.169262  16.841237  17.982451   \n",
       "7525   0.770657  16.431083  19.923425  15.502728  16.357902  19.036731   \n",
       "46441  0.583612  16.960252  12.600773  15.191264  16.295243  17.753734   \n",
       "14135  0.746200  16.831720  16.474822  16.902862  17.215572  15.038436   \n",
       "\n",
       "              57         58       59  \n",
       "6100   14.882141  53.166476     left  \n",
       "30848  20.813865  47.732244  unknown  \n",
       "26687  21.097822  56.996317  unknown  \n",
       "7525   21.465307  53.337011       no  \n",
       "46441  20.810784  58.502929  unknown  \n",
       "14135  16.477407  66.502537       on  \n",
       "\n",
       "[6 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df)\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 60000\n",
    "features = np.array(df)\n",
    "tr_x = features[:tr,0:58]\n",
    "tr_y = features[:tr,59]\n",
    "val_x = features[tr:,0:58]\n",
    "val_y = features[tr:,59]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mean = np.mean(tr_x, axis=0)\n",
    "tr_std = np.std(tr_x, axis = 0,dtype=np.float64)\n",
    "tr_xp = (tr_x - tr_mean[None,:])/tr_std[None,:]\n",
    "\n",
    "val_mean = np.mean(val_x, axis=0)\n",
    "val_std = np.std(val_x, axis = 0,dtype=np.float64)\n",
    "val_xp = (val_x - val_mean[None,:])/val_std[None,:]\n",
    "\n",
    "lab = LabelEncoder()\n",
    "tr_yp= lab.fit_transform(tr_y)\n",
    "val_yp= lab.fit_transform(val_y)\n",
    "\n",
    "n_words= np.unique(tr_yp)\n",
    "n_classes = len(n_words)\n",
    "n_features = tr_xp.shape[1]\n",
    "\n",
    "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(range(n_classes))\n",
    "tr_yoh = label_binarizer.transform(tr_yp)\n",
    "val_yoh = label_binarizer.transform(val_yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components ='mle', svd_solver = 'full')\n",
    "pca.fit(tr_xp)\n",
    "tr_pca = pca.transform(tr_xp)\n",
    "val_pca = pca.transform(val_xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 700\n",
    "n_nodes_hl2 = 700\n",
    "n_nodes_hl3 = 100\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "x = tf.placeholder('float',[None,n_features-1])\n",
    "y = tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "\n",
    "    # initializing weights and biases for the hidden layers and the output layer\n",
    "    hidden_l1 = {'weights': tf.Variable(tf.random_normal([n_features-1,n_nodes_hl1])), \n",
    "                 'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_l2 = {'weights': tf.Variable(tf.random_normal([n_nodes_hl1,n_nodes_hl2])), \n",
    "                 'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_l3 = {'weights': tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl3])), \n",
    "                 'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_l = {'weights': tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])), \n",
    "                 'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    # computing the ouput of each layer and applying a non-linearity at the end of each layer computation\n",
    "    l1 = tf.add(tf.matmul(data, hidden_l1['weights']), hidden_l1['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1, hidden_l2['weights']), hidden_l2['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2, hidden_l3['weights']), hidden_l3['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.add(tf.matmul(l3, output_l['weights']), output_l['biases'])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "\n",
    "    # learning rate = 0.001\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "    # one epoch = one cycle of feed-forward and backprop\n",
    "    n_epochs = 20 \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0\n",
    "            for index, offset in enumerate(range(0, tr, batch_size)):\n",
    "                x_epoch, y_epoch = np.array(tr_pca[offset: offset + batch_size,:]), np.array(tr_yoh[offset: offset + batch_size])\n",
    "                _, c = sess.run([optimizer, cost], feed_dict ={x:x_epoch, y:y_epoch}) \n",
    "                epoch_loss +=c\n",
    "#             if (epoch%50 == 0):\n",
    "            print ('Epoch', epoch, 'completed out of', n_epochs, 'loss:', epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy  = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', accuracy.eval({x:val_pca, y:val_yoh}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 20 loss: 2045677.29297\n",
      "Epoch 1 completed out of 20 loss: 877019.774414\n",
      "Epoch 2 completed out of 20 loss: 581285.978516\n",
      "Epoch 3 completed out of 20 loss: 406963.213928\n",
      "Epoch 4 completed out of 20 loss: 257534.247589\n",
      "Epoch 5 completed out of 20 loss: 50071.2390528\n",
      "Epoch 6 completed out of 20 loss: 3969.1550386\n",
      "Epoch 7 completed out of 20 loss: 1608.42699087\n",
      "Epoch 8 completed out of 20 loss: 1017.48251891\n",
      "Epoch 9 completed out of 20 loss: 767.722209573\n",
      "Epoch 10 completed out of 20 loss: 640.626298785\n",
      "Epoch 11 completed out of 20 loss: 572.572470784\n",
      "Epoch 12 completed out of 20 loss: 532.74825573\n",
      "Epoch 13 completed out of 20 loss: 505.988672972\n",
      "Epoch 14 completed out of 20 loss: 487.209271431\n",
      "Epoch 15 completed out of 20 loss: 476.010565042\n",
      "Epoch 16 completed out of 20 loss: 467.322083116\n",
      "Epoch 17 completed out of 20 loss: 463.427080274\n",
      "Epoch 18 completed out of 20 loss: 458.370245099\n",
      "Epoch 19 completed out of 20 loss: 454.463867664\n",
      "Accuracy: 0.627562\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
